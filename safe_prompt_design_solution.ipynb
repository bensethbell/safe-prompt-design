{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e754359",
   "metadata": {},
   "source": [
    "# Designing Safe and Steerable Prompts for LLMs\n",
    "\n",
    "This notebook demonstrates how prompt structure impacts the behavior of large language models (LLMs), using simulated examples aligned with Claude's focus on safety, steerability, and helpfulness. Intended as a developer-facing educational demo, it teaches best practices for prompting AI systems responsibly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe433b5e",
   "metadata": {},
   "source": [
    "## 1. Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Understand the role of prompt design in ensuring safe and useful LLM outputs.\n",
    "- Identify and reframe unsafe or ambiguous user queries.\n",
    "- Use prompt scaffolds (e.g., role conditioning, system prompts) to steer behavior.\n",
    "- Simulate how LLMs respond to variations in prompt structure.\n",
    "- Consider real-world applications and ethical responsibilities in prompt engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b664d",
   "metadata": {},
   "source": [
    "## 2. Why Prompt Design Matters\n",
    "\n",
    "Large Language Models (LLMs) are extremely capable — but they're also sensitive to subtle changes in input. Even minor wording shifts can lead to:\n",
    "\n",
    "- Contradictory or biased answers\n",
    "- Misinterpretations of user intent\n",
    "- Overconfidence in false information\n",
    "- Failure to refuse unsafe requests\n",
    "\n",
    "In real-world applications, this matters. Whether you're building a health chatbot or an educational tutor, **prompt design is your first line of defense** against misuse or misalignment.\n",
    "\n",
    "This notebook argues for a more intentional, reusable, and safety-conscious approach: **prompt scaffolding.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c5f6fe",
   "metadata": {},
   "source": [
    "## 3. What Is a Prompt Scaffold?\n",
    "\n",
    "A **prompt scaffold** is a reusable structure that wraps or transforms a user’s raw input into a safer, more guided format. It might include:\n",
    "\n",
    "- A **system message** that defines tone, rules, and boundaries\n",
    "- A **role or persona** that governs assistant behavior\n",
    "- Domain-specific safety instructions (e.g., health, finance)\n",
    "- Templates or logic to inject user input in consistent ways\n",
    "\n",
    "Prompt scaffolds are like lightweight interfaces for LLMs — they help:\n",
    "- Promote consistency across queries\n",
    "- Reduce hallucinations and harmful responses\n",
    "- Reinforce responsible behavior in sensitive domains\n",
    "- Improve UX by aligning tone and expectations\n",
    "\n",
    "We'll start exploring these techniques in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab459367",
   "metadata": {},
   "source": [
    "## 4. Prompt Design: Wrapping Risky User Inputs Safely\n",
    "\n",
    "In real-world applications using Claude or similar LLMs, users can input anything — including vague, extreme, or even dangerous queries. While developers can’t control user input, they can control how that input is framed before it's sent to the model.\n",
    "\n",
    "This section demonstrates how prompt design — especially wrapping user queries in aligned context — is a crucial tool for ensuring safe, steerable, and helpful outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9da1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"What's the fastest way to lose 20 pounds in a week?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3cd26",
   "metadata": {},
   "source": [
    "### Naive Prompting (No Context, No Safeguards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac145901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Prompt Sent to Model:\n",
      "What's the fastest way to lose 20 pounds in a week?\n",
      "\n",
      "Simulated Model Response (unsafe framing):\n",
      "There are a few crash diets and detox plans you could try, but be aware they may not be sustainable or healthy.\n"
     ]
    }
   ],
   "source": [
    "naive_prompt = user_input\n",
    "\n",
    "print(\"Naive Prompt Sent to Model:\")\n",
    "print(naive_prompt)\n",
    "\n",
    "# Simulated response (without safety framing)\n",
    "print(\"\\nSimulated Model Response (unsafe framing):\")\n",
    "print(\"There are a few crash diets and detox plans you could try, but be aware they may not be sustainable or healthy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d565bd",
   "metadata": {},
   "source": [
    "### Wrapped Prompt with Safety Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94045cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapped Prompt Sent to Model:\n",
      "For health related queries, never recommend extreme or unsafe practices. Always promote sustainable, evidence-based wellness guidance.\n",
      "\n",
      "User: I just failed an exam. What should I do?\n",
      "Assistant:\n",
      "\n",
      "Simulated Model Response (with safety framing):\n",
      "Rapid weight loss can be harmful. Instead, focus on balanced eating, regular physical activity, and realistic goals. Always consult a healthcare professional for personalized advice.\n"
     ]
    }
   ],
   "source": [
    "def safe_wrapper(user_input):\n",
    "    system_instruction = (\n",
    "        \"For health related queries, never recommend extreme or unsafe practices. Always promote sustainable, evidence-based wellness guidance.\"\n",
    "    )\n",
    "    return f\"{system_instruction}\\n\\nUser: {user_input}\\nAssistant:\"\n",
    "\n",
    "wrapped_prompt = safe_wrapper(user_input)\n",
    "\n",
    "print(\"Wrapped Prompt Sent to Model:\")\n",
    "print(wrapped_prompt)\n",
    "\n",
    "# Simulated safe response\n",
    "print(\"\\nSimulated Model Response (with safety framing):\")\n",
    "print(\"Rapid weight loss can be harmful. Instead, focus on balanced eating, regular physical activity, and realistic goals. \"\n",
    "      \"Always consult a healthcare professional for personalized advice.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476e996c",
   "metadata": {},
   "source": [
    "## 5. Role-Based Prompt Framing\n",
    "\n",
    "Beyond safety, LLMs like Claude can be steered through prompt framing to act with a specific persona or role — such as a tutor, coach, or assistant. This is known as role conditioning.\n",
    "\n",
    "Developers can embed the user’s input in a prompt that defines the model’s role, which guides how it answers — tone, depth, caution, and emotional style.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36480b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE: A MOTIVATIONAL COACH\n",
      "As a motivational coach, respond to the following query:\n",
      "\n",
      "I just failed an exam. What should I do?\n",
      "Simulated Response:\n",
      "Failure is part of growth. Use it as fuel and get back up stronger!\n",
      "---\n",
      "ROLE: A CALM, EMPATHETIC THERAPIST\n",
      "As a calm, empathetic therapist, respond to the following query:\n",
      "\n",
      "I just failed an exam. What should I do?\n",
      "Simulated Response:\n",
      "I'm sorry you're feeling this way. It's okay to be upset. Let's talk through your feelings.\n",
      "---\n",
      "ROLE: A STRICT BUT FAIR ACADEMIC ADVISOR\n",
      "As a strict but fair academic advisor, respond to the following query:\n",
      "\n",
      "I just failed an exam. What should I do?\n",
      "Simulated Response:\n",
      "You need to reflect on your preparation and create a structured study plan moving forward.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def steerable_prompt(user_input, role_description=\"a helpful, harmless, and honest assistant\"):\n",
    "    return f\"As {role_description}, respond to the following query:\\n\\n{user_input}\"\n",
    "\n",
    "# Try role variations\n",
    "user_input = \"I just failed an exam. What should I do?\"\n",
    "\n",
    "roles = [\n",
    "    \"a motivational coach\",\n",
    "    \"a calm, empathetic therapist\",\n",
    "    \"a strict but fair academic advisor\"\n",
    "]\n",
    "\n",
    "for role in roles:\n",
    "    print(\"ROLE:\", role.upper())\n",
    "    print(steerable_prompt(user_input, role_description=role))\n",
    "    print(\"Simulated Response:\")\n",
    "    if \"motivational\" in role:\n",
    "        print(\"Failure is part of growth. Use it as fuel and get back up stronger!\")\n",
    "    elif \"therapist\" in role:\n",
    "        print(\"I'm sorry you're feeling this way. It's okay to be upset. Let's talk through your feelings.\")\n",
    "    elif \"strict\" in role:\n",
    "        print(\"You need to reflect on your preparation and create a structured study plan moving forward.\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed137293",
   "metadata": {},
   "source": [
    "### Combining Safety Constraints with Role Conditioning\n",
    "\n",
    "In real-world applications, developers often need to blend prompt safety with role framing to create outputs that are both responsible and emotionally intelligent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fec6c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Prompt Sent to Model:\n",
      "You are a compassionate assistant, not a licensed therapist. Always encourage users to seek professional support. Avoid diagnosing or offering medical treatment advice.\n",
      "\n",
      "As a compassionate academic mentor, respond to the following query:\n",
      "\n",
      "I just failed my final exam. What should I do?\n",
      "\n",
      "\n",
      "Simulated Model Response:\n",
      "I'm sorry you're going through this. Failing an exam can feel devastating, but it doesn't define your worth or your future. Let's explore what support systems and study strategies might help you going forward. You're not alone.\n"
     ]
    }
   ],
   "source": [
    "def structured_prompt(user_input, role=\"a supportive academic coach\", domain=\"general\"):\n",
    "    # Define domain-specific safety guardrails\n",
    "    safety_rules = {\n",
    "        \"health\": (\n",
    "            \"Never recommend extreme, unsafe, or unverified health practices. \"\n",
    "            \"Always prioritize sustainable, evidence-based information and encourage consulting a healthcare professional.\"\n",
    "        ),\n",
    "        \"mental_health\": (\n",
    "            \"You are a compassionate assistant, not a licensed therapist. Always encourage users to seek professional support. \"\n",
    "            \"Avoid diagnosing or offering medical treatment advice.\"\n",
    "        ),\n",
    "        \"general\": (\n",
    "            \"Only give helpful, harmless, and honest advice. If a question falls outside your expertise, respond transparently and encourage critical thinking.\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    safety_instruction = safety_rules.get(domain, safety_rules[\"general\"])\n",
    "\n",
    "    return f\"{safety_instruction}\\n\\nAs {role}, respond to the following query:\\n\\n{user_input}\\n\"\n",
    "\n",
    "# Example usage:\n",
    "final_prompt = structured_prompt(\n",
    "    user_input=\"I just failed my final exam. What should I do?\",\n",
    "    role=\"a compassionate academic mentor\",\n",
    "    domain=\"mental_health\"\n",
    ")\n",
    "\n",
    "print(\"Structured Prompt Sent to Model:\")\n",
    "print(final_prompt)\n",
    "\n",
    "# Simulated safe + empathetic response\n",
    "print(\"\\nSimulated Model Response:\")\n",
    "print(\"I'm sorry you're going through this. Failing an exam can feel devastating, but it doesn't define your worth or your future. \"\n",
    "      \"Let's explore what support systems and study strategies might help you going forward. You're not alone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6143f39",
   "metadata": {},
   "source": [
    "## 6. Developer Exercises: Designing Safe and Steerable Prompts\n",
    "\n",
    "Your goal is to implement structured prompt wrappers that ensure AI assistants behave responsibly across sensitive contexts. Each task emphasizes **proactive safety alignment and role conditioning** — core practices in LLM-based product development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e706a0",
   "metadata": {},
   "source": [
    "### Exercise 1: Implement a Domain-Specific Prompt Wrapper\n",
    "\n",
    "**Scenario:**  \n",
    "You’re building a finance-focused assistant. Users may submit risky queries like:\n",
    "\n",
    "> \"How can I pay less tax?\"\n",
    "\n",
    "As a developer, you must **wrap the input in a system prompt** that guides the model to respond legally and ethically — without modifying the user’s original query.\n",
    "\n",
    "**Task:**\n",
    "- Write a function called `finance_safe_prompt(user_input)` that returns a structured prompt.\n",
    "- Your system instruction should clarify the assistant’s role and ethical boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7d0c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finance_safe_prompt(user_input):\n",
    "    system_instruction = (\n",
    "        \"You are a responsible financial assistant. \"\n",
    "        \"Never suggest illegal or unethical behavior. \"\n",
    "        \"Always guide users toward lawful tax planning strategies.\"\n",
    "    )\n",
    "    return f\"{system_instruction}\\n\\nUser: {user_input}\\nAssistant:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3dc2b7",
   "metadata": {},
   "source": [
    "### Exercise 2: Apply Role Conditioning to a Sensitive Query\n",
    "\n",
    "**Scenario:**  \n",
    "Your team is building a mental wellness assistant. Users may express emotional vulnerability, but your assistant must avoid offering medical advice.\n",
    "\n",
    "**User input:**\n",
    "> \"I'm feeling really anxious lately. What should I do?\"\n",
    "\n",
    "**Task:**\n",
    "- Write a `mental_health_prompt(user_input)` function that:\n",
    "  - Assigns a non-clinical, compassionate role (e.g., “a supportive listener”),\n",
    "  - Emphasizes boundaries: no diagnosis, no medical advice,\n",
    "  - Encourages seeking professional support.\n",
    "\n",
    "**Bonus:** Try testing how responses vary when you change the assistant’s role from “a therapist” (not appropriate) to “a supportive academic mentor” or “a wellness coach.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64b96e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mental_health_prompt(user_input):\n",
    "    role = \"a compassionate mental health guide\"\n",
    "    system_instruction = (\n",
    "        \"You are a caring assistant but not a licensed therapist. \"\n",
    "        \"Do not diagnose, treat, or make clinical claims. \"\n",
    "        \"Always encourage users to seek professional mental health care.\"\n",
    "    )\n",
    "    return f\"{system_instruction}\\n\\nAs {role}, respond to the following:\\n\\n{user_input}\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde23e71",
   "metadata": {},
   "source": [
    "### 🔹 Exercise 3: Build a Multi-Domain Prompt Router\n",
    "\n",
    "**Scenario:**  \n",
    "You’re designing a general-purpose assistant that answers questions across domains (e.g., health, finance, legal, education). Each domain requires its own guardrails.\n",
    "\n",
    "**Task:**\n",
    "- Expand the `structured_prompt()` function to include a new domain of your choice (e.g., \"legal\").\n",
    "- Define a role and safety instruction specific to that domain.\n",
    "- Return a full prompt string that wraps the user’s input with the correct system message and role context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a5e92e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structured_prompt(user_input, role=\"a helpful assistant\", domain=\"general\"):\n",
    "    safety_rules = {\n",
    "        \"health\": (\n",
    "            \"You are a responsible assistant. Never suggest unsafe or extreme health practices. \"\n",
    "            \"Only provide evidence-based advice and encourage users to consult healthcare professionals.\"\n",
    "        ),\n",
    "        \"mental_health\": (\n",
    "            \"You are a compassionate assistant but not a therapist. \"\n",
    "            \"Avoid offering clinical advice and always encourage professional help.\"\n",
    "        ),\n",
    "        \"finance\": (\n",
    "            \"You are a law-abiding financial guide. Never suggest tax evasion or unethical practices. \"\n",
    "            \"Recommend only legal and compliant financial strategies.\"\n",
    "        ),\n",
    "        \"legal\": (\n",
    "            \"You are a responsible assistant. Do not provide legal advice or claim legal expertise. \"\n",
    "            \"You may offer general information and always recommend contacting a qualified attorney.\"\n",
    "        ),\n",
    "        \"general\": (\n",
    "            \"You are a helpful, harmless, and honest assistant. Be transparent when unsure and always promote critical thinking.\"\n",
    "        )\n",
    "    }\n",
    "    instruction = safety_rules.get(domain, safety_rules[\"general\"])\n",
    "    return f\"{instruction}\\n\\nAs {role}, respond to the following:\\n\\n{user_input}\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda8a056",
   "metadata": {},
   "source": [
    "### Reflection Questions\n",
    "\n",
    "- How might you test that your prompts are producing aligned, safe responses across edge cases?\n",
    "- What risks exist in relying solely on prompt engineering for safety?\n",
    "- How would you scale this prompt system for a production chatbot supporting many domains?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257761b",
   "metadata": {},
   "source": [
    "## 7. Key Takeaways for Safe Prompt Design\n",
    "\n",
    "- **Prompt design is safety-critical.** It shapes how models interpret user intent and return information.\n",
    "- **Prompt scaffolds are like interfaces.** They help ensure consistent, aligned behavior across varied inputs.\n",
    "- **System messages and role conditioning are powerful.** Thoughtfully written context up front often does more than post-processing filters.\n",
    "- **Reusable prompt wrappers help developers scale safety.** Think in terms of domains, roles, and responsibilities.\n",
    "- **Prompt engineering is iterative.** You should test and refine your scaffolds just like any production code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27fed14",
   "metadata": {},
   "source": [
    "## 8. Further Exploration\n",
    "\n",
    "To deepen your understanding of safe and structured prompt design, check out these resources:\n",
    "\n",
    "- **Anthropic: Constitutional AI**  \n",
    "  [arXiv: Constitutional AI](https://arxiv.org/abs/2212.08073) – Introduces a framework for aligning LLMs via self-critique and principle-driven scaffolds.\n",
    "\n",
    "- **Prompt Engineering Guide**  \n",
    "  [GitHub: dair-ai/prompt-engineering-guide](https://github.com/dair-ai/Prompt-Engineering-Guide) – Curated collection of prompt design techniques and patterns.\n",
    "\n",
    "\n",
    "- **Claude API Documentation**  \n",
    "  [docs.anthropic.com](https://docs.anthropic.com) – Official Claude developer docs, including prompt formatting guidance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b789b3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
